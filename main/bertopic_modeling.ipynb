{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup used\n",
    "\n",
    "Ram = 32 GB <br>\n",
    "GPU = GeForce 3060ti RTX 6 GB <br>\n",
    "CPU = AMD Ryzen 9 5900X 12-Core Processor, 3701 MHz, 12 cores, 24 logical cores\n",
    "\n",
    "All packages where installed inside a virtual conda environment on WSL (Windows Subsystem for Linux)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import nltk\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from cuml.cluster import HDBSCAN # We are using the GPU accelerated version of HDBSCAN\n",
    "from cuml.manifold import UMAP # We are using the GPU accelerated version of UMAP\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize functions here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_topic_coherence(model, frame):\n",
    "\n",
    "    topics = model.topics_\n",
    "\n",
    "    # Preprocess Documents\n",
    "    documents = pd.DataFrame({\"Document\": frame['content_corrected'],\n",
    "                            \"ID\": range(len(frame['content_corrected'])),\n",
    "                            \"Topic\": topics})\n",
    "    documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\n",
    "    cleaned_docs = model._preprocess_text(documents_per_topic.Document.values)\n",
    "\n",
    "    # Extract vectorizer and analyzer from BERTopic\n",
    "    vectorizer = model.vectorizer_model\n",
    "    analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "    # Extract features for Topic Coherence evaluation\n",
    "    words = vectorizer.get_feature_names()\n",
    "    tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "    dictionary = corpora.Dictionary(tokens)\n",
    "    corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "    topic_words = [[words for words, _ in model.get_topic(topic)]\n",
    "                for topic in range(len(set(topics))-1)]\n",
    "\n",
    "    # Evaluate\n",
    "    coherence_model = CoherenceModel(topics=topic_words,\n",
    "                                    texts=tokens,\n",
    "                                    corpus=corpus,\n",
    "                                    dictionary=dictionary,\n",
    "                                    coherence='c_v',\n",
    "                                    processes=10)\n",
    "\n",
    "    return coherence_model.get_coherence()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_topic_diversity(model):\n",
    "\n",
    "    topics = model.topics_\n",
    "\n",
    "    model_output_test = {}\n",
    "    model_output_test['topics'] = [[z[0] for z in model.get_topic(x)] for x in set(topics)]\n",
    "    metric = TopicDiversity(topk=3)\n",
    "\n",
    "    return metric.score(model_output_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_690/3651187523.py:5: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_amazon = pd.read_csv(f'preprocessed_data/prep_amazon_v4.csv')\n"
     ]
    }
   ],
   "source": [
    "df_netflix = pd.read_csv(f'preprocessed_data/prep_netflix_v4.csv')\n",
    "df_youtube = pd.read_csv(f'preprocessed_data/prep_youtube_v4.csv')\n",
    "df_whatsapp = pd.read_csv(f'preprocessed_data/prep_whatsapp_v4.csv')\n",
    "df_paypal = pd.read_csv(f'preprocessed_data/prep_paypal_v4.csv')\n",
    "df_amazon = pd.read_csv(f'preprocessed_data/prep_amazon_v4.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize CountVectorizer fron ngram extraction and stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/denis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model\n",
    "\n",
    "Depending on the dataset, the n_neighbors argument may need to be changed (higher n_neighbors gives a more broader look on the data, and vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=5, n_components=5, min_dist=0.0, metric='cosine', verbose=True, random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=5, metric='euclidean', cluster_selection_method='eom', prediction_data=True, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_netflix = BERTopic(embedding_model='all-mpnet-base-v2', vectorizer_model=vectorizer_model, umap_model=umap_model, hdbscan_model=hdbscan_model, language='english', calculate_probabilities=True, verbose=True)\n",
    "topics_netflix, probs_netflix = topic_model_netflix.fit_transform(list(df_netflix['content_corrected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_netflix.reduce_topics(df_netflix['content_corrected'], nr_topics='auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=1500, verbose=True, random_state=42)\n",
    "topic_model_youtube = BERTopic(embedding_model='all-mpnet-base-v2', vectorizer_model=vectorizer_model, umap_model=umap_model, hdbscan_model=hdbscan_model, language='english', calculate_probabilities=True, verbose=True)\n",
    "topics_youtube, probs_youtube = topic_model_youtube.fit_transform(list(df_youtube['content_corrected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_youtube.reduce_topics(df_youtube['content_corrected'], nr_topics='auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training WhatsApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_whatsapp = BERTopic(embedding_model='all-mpnet-base-v2', vectorizer_model=vectorizer_model, umap_model=umap_model, hdbscan_model=hdbscan_model, language='english', calculate_probabilities=True, verbose=True)\n",
    "topics_whatsapp, probs_whatsapp = topic_model_whatsapp.fit_transform(list(df_whatsapp['content_corrected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_whatsapp.reduce_topics(df_whatsapp['content_corrected'], nr_topics = 'auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training PayPal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_paypal = BERTopic(embedding_model='all-mpnet-base-v2', vectorizer_model=vectorizer_model, umap_model=umap_model, hdbscan_model=hdbscan_model, language='english', calculate_probabilities=True, verbose=True)\n",
    "topics_paypal, probs_paypal = topic_model_paypal.fit_transform(list(df_paypal['content_corrected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_paypal.reduce_topics(df_paypal['content_corrected'], nr_topics='auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_amazon = BERTopic(embedding_model='all-mpnet-base-v2', vectorizer_model=vectorizer_model, umap_model=umap_model, hdbscan_model=hdbscan_model, language='english', calculate_probabilities=True, verbose=True)\n",
    "topics_amazon, probs_amazon = topic_model_amazon.fit_transform(list(df_amazon['content_corrected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_amazon.reduce_topics(df_amazon['content_corrected'], nr_topics='auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_netflix.save('models/topicmodel_netflix_hdbscan_v1.model')\n",
    "topic_model_youtube.save('models/topicmodel_youtube_hdbscan_v1.model')\n",
    "topic_model_whatsapp.save('models/topicmodel_whatsapp_hdbscan_v1.model')\n",
    "topic_model_paypal.save('models/topicmodel_paypal_hdbscan_v1.model')\n",
    "topic_model_amazon.save('models/topicmodel_amazon_hdbscan_v1.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_netflix = BERTopic.load('models/topicmodel_netflix_hdbscan_v1.model')\n",
    "topic_model_youtube = BERTopic.load('models/topicmodel_youtube_hdbscan_v1.model')\n",
    "topic_model_whatsapp = BERTopic.load('models/topicmodel_whatsapp_hdbscan_v1.model')\n",
    "topic_model_paypal = BERTopic.load('models/topicmodel_paypal_hdbscan_v1.model')\n",
    "topic_model_amazon = BERTopic.load('models/topicmodel_amazon_hdbscan_v1.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.490743485683326\n",
      "0.5164818573753166\n",
      "0.4635664298306533\n",
      "0.5097446310724613\n",
      "0.49839795241255097\n"
     ]
    }
   ],
   "source": [
    "print(topic_model_netflix.get_topic_info()['Count'].loc[topic_model_netflix.get_topic_info().index[0]]/len(df_netflix))\n",
    "print(topic_model_youtube.get_topic_info()['Count'].loc[topic_model_youtube.get_topic_info().index[0]]/len(df_youtube))\n",
    "print(topic_model_whatsapp.get_topic_info()['Count'].loc[topic_model_whatsapp.get_topic_info().index[0]]/len(df_whatsapp))\n",
    "print(topic_model_paypal.get_topic_info()['Count'].loc[topic_model_paypal.get_topic_info().index[0]]/len(df_paypal))\n",
    "print(topic_model_amazon.get_topic_info()['Count'].loc[topic_model_amazon.get_topic_info().index[0]]/len(df_amazon))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics_netflix = BERTopic.reduce_outliers(topic_model_netflix, df_netflix['content_corrected'], topic_model_netflix.topics_, probabilities=topic_model_netflix.probabilities_, \n",
    "                             threshold=0.010, strategy=\"probabilities\")\n",
    "topic_model_netflix.update_topics(df_netflix['content_corrected'], topics=new_topics_netflix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics_youtube = BERTopic.reduce_outliers(topic_model_youtube, df_youtube['content_corrected'], topic_model_youtube.topics_, probabilities=topic_model_youtube.probabilities_, \n",
    "                             threshold=0.010, strategy=\"probabilities\")\n",
    "topic_model_youtube.update_topics(df_youtube['content_corrected'], topics=new_topics_youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics_whatsapp = BERTopic.reduce_outliers(topic_model_whatsapp, df_whatsapp['content_corrected'], topic_model_whatsapp.topics_, probabilities=topic_model_whatsapp.probabilities_, \n",
    "                             threshold=0.010, strategy=\"probabilities\")\n",
    "topic_model_whatsapp.update_topics(df_whatsapp['content_corrected'], topics=new_topics_whatsapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics_paypal = BERTopic.reduce_outliers(topic_model_paypal, df_paypal['content_corrected'], topic_model_paypal.topics_, probabilities=topic_model_paypal.probabilities_, \n",
    "                             threshold=0.010, strategy=\"probabilities\")\n",
    "topic_model_paypal.update_topics(df_paypal['content_corrected'], topics=new_topics_paypal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics_amazon = BERTopic.reduce_outliers(topic_model_amazon, df_amazon['content_corrected'], topic_model_amazon.topics_, probabilities=topic_model_amazon.probabilities_, \n",
    "                             threshold=0.010, strategy=\"probabilities\")\n",
    "topic_model_amazon.update_topics(df_amazon['content_corrected'], topics=new_topics_amazon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving new model versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_netflix.save('models/topicmodel_netflix_hdbscan_v2.model')\n",
    "topic_model_youtube.save('models/topicmodel_youtube_hdbscan_v2.model')\n",
    "topic_model_whatsapp.save('models/topicmodel_whatsapp_hdbscan_v2.model')\n",
    "topic_model_paypal.save('models/topicmodel_paypal_hdbscan_v2.model')\n",
    "topic_model_amazon.save('models/topicmodel_amazon_hdbscan_v2.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading new model versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_netflix = BERTopic.load('models/topicmodel_netflix_hdbscan_v2.model')\n",
    "topic_model_youtube = BERTopic.load('models/topicmodel_youtube_hdbscan_v2.model')\n",
    "topic_model_whatsapp = BERTopic.load('models/topicmodel_whatsapp_hdbscan_v2.model')\n",
    "topic_model_paypal = BERTopic.load('models/topicmodel_paypal_hdbscan_v2.model')\n",
    "topic_model_amazon = BERTopic.load('models/topicmodel_amazon_hdbscan_v2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>15235</td>\n",
       "      <td>-1_movies_good_you_like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>5067</td>\n",
       "      <td>15_freezes_audio_video_freezing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>2389</td>\n",
       "      <td>23_failure_1001_error_1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>2070</td>\n",
       "      <td>8_payment_card_repay_method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2047</td>\n",
       "      <td>2_movies_best_great_nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>1084</td>\n",
       "      <td>5</td>\n",
       "      <td>1084_85_88_myth_reflects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>1086</td>\n",
       "      <td>5</td>\n",
       "      <td>1086_locked_geez_unlocked_indeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1090</td>\n",
       "      <td>5</td>\n",
       "      <td>1090_language_filter_voiceover_dubbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1092</td>\n",
       "      <td>5</td>\n",
       "      <td>1092_minimize_minimizes_min_suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>1080</td>\n",
       "      <td>5</td>\n",
       "      <td>1080_dozens_results_clever_invest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic  Count                                   Name\n",
       "0        -1  15235                -1_movies_good_you_like\n",
       "16       15   5067        15_freezes_audio_video_freezing\n",
       "24       23   2389             23_failure_1001_error_1023\n",
       "9         8   2070            8_payment_card_repay_method\n",
       "3         2   2047               2_movies_best_great_nice\n",
       "...     ...    ...                                    ...\n",
       "1085   1084      5               1084_85_88_myth_reflects\n",
       "1087   1086      5       1086_locked_geez_unlocked_indeed\n",
       "1091   1090      5  1090_language_filter_voiceover_dubbed\n",
       "1093   1092      5       1092_minimize_minimizes_min_suck\n",
       "1081   1080      5      1080_dozens_results_clever_invest\n",
       "\n",
       "[1134 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_netflix.get_topic_info().sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>16310</td>\n",
       "      <td>-1_you_app_premium_like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>8808</td>\n",
       "      <td>10_crashing_freezes_crashes_freezing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8726</td>\n",
       "      <td>1_ads_ad_advertisements_too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4940</td>\n",
       "      <td>0_quality_resolution_480p_1080p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>3436</td>\n",
       "      <td>5_loading_working_load_connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1005</td>\n",
       "      <td>5</td>\n",
       "      <td>1005_luminosity_buffoons_interfaces_mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1069</td>\n",
       "      <td>5</td>\n",
       "      <td>1069_29gb_literary_hung_downloaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>994</td>\n",
       "      <td>5</td>\n",
       "      <td>994_exotic_animals_animal_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1045</td>\n",
       "      <td>5</td>\n",
       "      <td>1045_processor_880_surly_fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1006</td>\n",
       "      <td>5</td>\n",
       "      <td>1006_subscriptions_stall_urgently_intended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1098 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic  Count                                        Name\n",
       "0        -1  16310                     -1_you_app_premium_like\n",
       "11       10   8808        10_crashing_freezes_crashes_freezing\n",
       "2         1   8726                 1_ads_ad_advertisements_too\n",
       "1         0   4940             0_quality_resolution_480p_1080p\n",
       "6         5   3436           5_loading_working_load_connection\n",
       "...     ...    ...                                         ...\n",
       "1006   1005      5     1005_luminosity_buffoons_interfaces_mon\n",
       "1070   1069      5          1069_29gb_literary_hung_downloaded\n",
       "995     994      5             994_exotic_animals_animal_train\n",
       "1046   1045      5            1045_processor_880_surly_fiction\n",
       "1007   1006      5  1006_subscriptions_stall_urgently_intended\n",
       "\n",
       "[1098 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_youtube.get_topic_info().sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>8627</td>\n",
       "      <td>-1_app_and_that_it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>4249</td>\n",
       "      <td>6_30_seconds_videos_video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>3752</td>\n",
       "      <td>9_call_connecting_calls_reconnecting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2573</td>\n",
       "      <td>3_family_friends_communication_easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>2247</td>\n",
       "      <td>11_online_seen_offline_last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>739</td>\n",
       "      <td>5</td>\n",
       "      <td>739_ujjawal_shivansh_seducing_terrorist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>736</td>\n",
       "      <td>5</td>\n",
       "      <td>736_elements_misses_dost_takes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>733</td>\n",
       "      <td>5</td>\n",
       "      <td>733_welcomed_disc_procedure_spending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>716</td>\n",
       "      <td>5</td>\n",
       "      <td>716_ave_mkt_tube_posting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>770</td>\n",
       "      <td>5</td>\n",
       "      <td>770_seen_vry_disabled_online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                     Name\n",
       "0       -1   8627                       -1_app_and_that_it\n",
       "7        6   4249                6_30_seconds_videos_video\n",
       "10       9   3752     9_call_connecting_calls_reconnecting\n",
       "4        3   2573      3_family_friends_communication_easy\n",
       "12      11   2247              11_online_seen_offline_last\n",
       "..     ...    ...                                      ...\n",
       "740    739      5  739_ujjawal_shivansh_seducing_terrorist\n",
       "737    736      5           736_elements_misses_dost_takes\n",
       "734    733      5     733_welcomed_disc_procedure_spending\n",
       "717    716      5                 716_ave_mkt_tube_posting\n",
       "771    770      5             770_seen_vry_disabled_online\n",
       "\n",
       "[792 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_whatsapp.get_topic_info().sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4758</td>\n",
       "      <td>1_link_card_bank_debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>4464</td>\n",
       "      <td>-1_you_to_for_account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3584</td>\n",
       "      <td>0_easy_quick_fast_convenient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>1807</td>\n",
       "      <td>29_ebay_seller_paypal_buyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>1376</td>\n",
       "      <td>7_crashing_crashes_open_keeps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>587</td>\n",
       "      <td>6</td>\n",
       "      <td>587_sorting_code_vpn_kicking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>603</td>\n",
       "      <td>6</td>\n",
       "      <td>603_leads_lift_surprised_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>541</td>\n",
       "      <td>6</td>\n",
       "      <td>541_button_indication_satisfactory_nervous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>589</td>\n",
       "      <td>5</td>\n",
       "      <td>589_transverse_congrats_explanatory_supports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>571</td>\n",
       "      <td>5</td>\n",
       "      <td>571_freezing_gesture_androids_boot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                          Name\n",
       "2        1   4758                        1_link_card_bank_debit\n",
       "0       -1   4464                         -1_you_to_for_account\n",
       "1        0   3584                  0_easy_quick_fast_convenient\n",
       "30      29   1807                   29_ebay_seller_paypal_buyer\n",
       "8        7   1376                 7_crashing_crashes_open_keeps\n",
       "..     ...    ...                                           ...\n",
       "588    587      6                  587_sorting_code_vpn_kicking\n",
       "604    603      6                603_leads_lift_surprised_error\n",
       "542    541      6    541_button_indication_satisfactory_nervous\n",
       "590    589      5  589_transverse_congrats_explanatory_supports\n",
       "572    571      5            571_freezing_gesture_androids_boot\n",
       "\n",
       "[626 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_paypal.get_topic_info().sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>5244</td>\n",
       "      <td>5_they_delivery_service_delivered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>4607</td>\n",
       "      <td>-1_to_you_the_but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3229</td>\n",
       "      <td>0_crashing_crashes_open_keeps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1907</td>\n",
       "      <td>3_password_sign_log_account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>1705</td>\n",
       "      <td>40_chat_customer_service_refund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>619</td>\n",
       "      <td>6</td>\n",
       "      <td>619_op_preferences_s20be_mam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>630</td>\n",
       "      <td>5</td>\n",
       "      <td>630_pmone_justomer_number_buddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>672</td>\n",
       "      <td>5</td>\n",
       "      <td>672_fa_crashare_oneplus7_lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>639</td>\n",
       "      <td>5</td>\n",
       "      <td>639_winning_deception_rigged_cheated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>642</td>\n",
       "      <td>5</td>\n",
       "      <td>642_gaming_shitware_keypress_agitating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                    Name\n",
       "6        5   5244       5_they_delivery_service_delivered\n",
       "0       -1   4607                       -1_to_you_the_but\n",
       "1        0   3229           0_crashing_crashes_open_keeps\n",
       "4        3   1907             3_password_sign_log_account\n",
       "41      40   1705         40_chat_customer_service_refund\n",
       "..     ...    ...                                     ...\n",
       "620    619      6            619_op_preferences_s20be_mam\n",
       "631    630      5         630_pmone_justomer_number_buddy\n",
       "673    672      5             672_fa_crashare_oneplus7_lo\n",
       "640    639      5    639_winning_deception_rigged_cheated\n",
       "643    642      5  642_gaming_shitware_keypress_agitating\n",
       "\n",
       "[682 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_amazon.get_topic_info().sort_values(by='Count', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example sentences for the most discussed topic for each app review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Put in my email and password and says incorrect password but on any other device it's fine\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_info = pd.merge(topic_model_netflix.get_document_info(df_netflix['content_corrected']), df_netflix, left_on='Document', right_on='content_corrected')\n",
    "topic_0_netflix = netflix_info[netflix_info['Topic'] == 0]\n",
    "\n",
    "topic_0_netflix[topic_0_netflix['Representative_document'] == True]\\\n",
    "    ['content'].loc[16491]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The new update for video quality is very annoying. It automatically either goes to 720p or goes to 144p and you have to manually set it to 480p/360p everytime. Please do fix this as son as possible.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_info = pd.merge(topic_model_youtube.get_document_info(df_youtube['content_corrected']), df_youtube, left_on='Document', right_on='content_corrected')\n",
    "topic_0_youtube = youtube_info[youtube_info['Topic'] == 0]\n",
    "\n",
    "topic_0_youtube[topic_0_youtube['Representative_document'] == True]\\\n",
    "    ['content'].loc[48171]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When I trying to restore my messages from google drive backup in whatsapp, I cannot restore. It is continuously showing that preparing to restore messages. But not restoring. Fix this bug.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatsapp_info = pd.merge(topic_model_whatsapp.get_document_info(df_whatsapp['content_corrected']), df_whatsapp, left_on='Document', right_on='content_corrected')\n",
    "topic_0_whatsapp = whatsapp_info[whatsapp_info['Topic'] == 0]\n",
    "\n",
    "topic_0_whatsapp[topic_0_whatsapp['Representative_document'] == True]\\\n",
    "    ['content'].loc[2809]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quick, fast and easy...nothing better.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paypal_info = pd.merge(topic_model_paypal.get_document_info(df_paypal['content_corrected']), df_paypal, left_on='Document', right_on='content_corrected')\n",
    "topic_0_paypal = paypal_info[paypal_info['Topic'] == 0]\n",
    "\n",
    "topic_0_paypal[topic_0_paypal['Representative_document'] == True]\\\n",
    "    ['content'].loc[34554]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Keeps crashing. Won't even open.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_info = pd.merge(topic_model_amazon.get_document_info(df_amazon['content_corrected']), df_amazon, left_on='Document', right_on='content_corrected')\n",
    "topic_0_amazon = amazon_info[amazon_info['Topic'] == 0]\n",
    "\n",
    "topic_0_amazon[topic_0_amazon['Representative_document'] == True]\\\n",
    "    ['content'].loc[32496]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Coherence\n",
    "\n",
    "Topic Coherence is a score that measures how similar words are within a topic. Values between -1 and 1, where the higher a value is the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_topic_coherence.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(f'Netflix topics have achieved a topic coherence of: {calc_topic_coherence(topic_model_netflix, df_netflix)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_topic_coherence.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(f'YouTube topics have achieved a topic coherence of: {calc_topic_coherence(topic_model_youtube, df_youtube)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_topic_coherence.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(f'WhatsApp topics have achieved a topic coherence of: {calc_topic_coherence(topic_model_whatsapp, df_whatsapp)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_topic_coherence.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(f'PayPal topics have achieved a topic coherence of: {calc_topic_coherence(topic_model_paypal, df_paypal)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_topic_coherence.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(f'Amazon topics have achieved a topic coherence of: {calc_topic_coherence(topic_model_amazon, df_amazon)}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved topic coherence for amazon to file: 100%|██████████| 5/5 [40:34<00:00, 486.83s/it]\n"
     ]
    }
   ],
   "source": [
    "del progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved topic diversity for amazon to file: 100%|██████████| 5/5 [00:00<00:00, 175.70it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Save result to txt\n",
    "\n",
    "progress_bar = tqdm(total=5)\n",
    "\n",
    "with open('results_topic_diversity_outlierR.txt', 'w', encoding='utf-8') as f:\n",
    "\n",
    "    progress_bar.set_description('Calculating topic diversity for netflix...')\n",
    "    f.write(f'Netflix topics have achieved a topic diversity of: {calc_topic_diversity(topic_model_netflix)}\\n')\n",
    "    progress_bar.update(1)\n",
    "    progress_bar.set_description('Saved topic diversity for netflix to file')\n",
    "    progress_bar.set_description('Calculating topic diversity for youtube...')\n",
    "    f.write(f'YouTube topics have achieved a topic diversity of: {calc_topic_diversity(topic_model_youtube)}\\n')\n",
    "    progress_bar.update(1)\n",
    "    progress_bar.set_description('Saved topic diversity for youtube to file')\n",
    "    progress_bar.set_description('Calculating topic diversity for whatsapp...')\n",
    "    f.write(f'WhatsApp topics have achieved a topic diversity of: {calc_topic_diversity(topic_model_whatsapp)}\\n')\n",
    "    progress_bar.update(1)\n",
    "    progress_bar.set_description('Saved topic diversity for whatsapp to file')\n",
    "    progress_bar.set_description('Calculating topic diversity for paypal...')\n",
    "    f.write(f'PayPal topics have achieved a topic diversity of: {calc_topic_diversity(topic_model_paypal)}\\n')\n",
    "    progress_bar.update(1)\n",
    "    progress_bar.set_description('Saved topic diversity for paypal to file')\n",
    "    progress_bar.set_description('Calculating topic diversity for amazon...')\n",
    "    f.write(f'Amazon topics have achieved a topic diversity of: {calc_topic_diversity(topic_model_amazon)}\\n')\n",
    "    progress_bar.update(1)\n",
    "    progress_bar.set_description('Saved topic diversity for amazon to file')\n",
    "\n",
    "del progress_bar\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuml_test5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
